{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXdG_md-NtFb",
    "outputId": "4d64af1b-b0f2-4389-ecb0-8030b4d58098"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 39
    },
    "id": "bLUQVSnGiudI",
    "outputId": "805b0c74-ac99-472e-fc36-11e5246419e7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-6a47df22-f57e-4797-a8d8-9a9fee2b33f9\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-6a47df22-f57e-4797-a8d8-9a9fee2b33f9\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfeF9M4NPe9N"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from cvxpy import *\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from numpy import linalg as LA\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import coo_array\n",
    "from scipy.optimize import nnls\n",
    "import multiprocessing as mp\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Non-spatial TopicScore"
   ],
   "metadata": {
    "id": "zktzKaKRwks6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def unpack_apply(all_args):\n",
    "    (func1d, axis, arr) = all_args\n",
    "    return np.apply_along_axis(func1d, axis, arr)\n",
    "\n",
    "\n",
    "def solveX_LS(data):\n",
    "    n, p, k = data[(data.size - 3) : (data.size)].astype(int)\n",
    "    d = data[0:p]\n",
    "    x_sol = nnls(A.transpose(), d)[0]\n",
    "    return x_sol"
   ],
   "metadata": {
    "id": "08UQDenfB-9R"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Ahat, D, E\n",
    "root_path = \"\"\n",
    "sample_idx = [\"BALBc-1\", \"BALBc-2\", \"BALBc-3\"]\n",
    "PATH_TO_MODELS = \"spleen_tscore_nonspatial\"\n",
    "n_topics = [3, 5, 8, 10]\n",
    "lamb = 0\n",
    "\n",
    "for sample in sample_idx:\n",
    "    print(f\"Sample {sample} starting...\")\n",
    "    print(\"---------------------------------\")\n",
    "    # Read D\n",
    "    D_path = f\"{sample}_D_unnorm\" + \".csv\"\n",
    "    D = pd.read_csv(root_path + D_path)\n",
    "    names = D.to_numpy()[:, 0]\n",
    "    D = D.to_numpy()[:, 1:]\n",
    "    D = D / D.sum(axis=1, keepdims=True)  # normalize to fraction\n",
    "    # Iterate for each n_topic\n",
    "    for n_topic in n_topics:\n",
    "        print(f\"Running n_topics={n_topic}, lambda={lamb}\\n\")\n",
    "        t = time.time()\n",
    "        path_to_train_model = (\n",
    "            \"_\".join(\n",
    "                (\n",
    "                    f\"{PATH_TO_MODELS}\",\n",
    "                    f\"{sample}\" f\"penalty={lamb}\",\n",
    "                    f\"topics={n_topic}\",\n",
    "                )\n",
    "            )\n",
    "            + \".pkl\"\n",
    "        )\n",
    "        # Read Ahat\n",
    "        Ahat_path = f\"{sample}_Ahat_\" + f\"{n_topic}\" + \".csv\"\n",
    "        Ahat = pd.read_csv(root_path + Ahat_path)\n",
    "        A = Ahat.to_numpy().transpose()\n",
    "        n, p = D.shape\n",
    "        k = A.shape[0]\n",
    "        # Run\n",
    "        data = np.concatenate(\n",
    "            (D.transpose(), np.tile([n, p, k], (n, 1)).transpose()), axis=0\n",
    "        )\n",
    "        chunks = [\n",
    "            (solveX_LS, 1, sub_arr)\n",
    "            for sub_arr in np.array_split(data.transpose(), mp.cpu_count())\n",
    "        ]\n",
    "        pool = Pool()\n",
    "        values = pool.map(unpack_apply, chunks)\n",
    "        res = np.concatenate(values)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        x = res.transpose()  # k*n\n",
    "        # edge = E[:,:-1].astype(int)\n",
    "        # edge_expand = np.zeros(2*m)\n",
    "        # edge_expand[::2] = edge[:,0]\n",
    "        # edge_expand[1::2] = edge[:,1]\n",
    "        # z = x[:,edge_expand.astype(int)] #k*2m\n",
    "        # u = np.zeros((k,2*m))\n",
    "        elapsed = time.time() - t\n",
    "        print(f\"Elapsed time={elapsed}\\n\")\n",
    "        with open(path_to_train_model, \"wb\") as f:\n",
    "            pkl.dump(x, f)"
   ],
   "metadata": {
    "id": "yDD_uSlWxu1e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spatial TopicScore"
   ],
   "metadata": {
    "id": "EkFWNOJ-xDXK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ADMM functions"
   ],
   "metadata": {
    "id": "ErzDLiDTwpGa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skDX_c0lgSYv"
   },
   "outputs": [],
   "source": [
    "def solveX(data, vars, edge_mat):\n",
    "    rho, lamb = data[(data.size - 6) : (data.size - 4)]\n",
    "    m, n, p, k = data[(data.size - 4) : (data.size)].astype(int)\n",
    "    nodenum = data[(data.size - 7)]\n",
    "    x = data[0:k]\n",
    "    d = data[k : (k + p)]\n",
    "    Z_k = np.concatenate(\n",
    "        (\n",
    "            vars[(edge_mat[:, 0] == nodenum), :k],\n",
    "            vars[(edge_mat[:, 1] == nodenum), k : 2 * k],\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    U_k = np.concatenate(\n",
    "        (\n",
    "            vars[(edge_mat[:, 0] == nodenum), 2 * k : 3 * k],\n",
    "            vars[(edge_mat[:, 1] == nodenum), 3 * k : 4 * k],\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    xnew = Variable(k)\n",
    "\n",
    "    g = 0.5 * square(norm(d - (xnew @ A)))\n",
    "    V = U_k - Z_k + vstack([xnew] * Z_k.shape[0])  # x - z + u\n",
    "    h = 0.5 * rho * sum(square(norm(V, axis=1)))\n",
    "    objective = Minimize(g + h)\n",
    "    constraints = []  # constraints = [xnew >= 0]\n",
    "    pr = Problem(objective, constraints)\n",
    "    result = pr.solve(solver=\"ECOS_BB\")\n",
    "\n",
    "    if result == None:\n",
    "        objective = Minimize(51 * g + 52 * h)\n",
    "        pr = Problem(objective, constraints)\n",
    "        result = pr.solve(verbose=False, warm_start=True)\n",
    "        if result == None:\n",
    "            print(\"SCALING BUG\")  # CVXOPT scaling issue\n",
    "            objective = Minimize(52 * g + 50 * h)\n",
    "            pr = Problem(objective, constraints)\n",
    "            result = pr.solve(verbose=False, warm_start=True)\n",
    "    return xnew.value\n",
    "\n",
    "\n",
    "def solveX_wrapper(args):\n",
    "    row, vars, edge = args\n",
    "    return solveX(row, vars=vars, edge=edge)\n",
    "\n",
    "\n",
    "def solveX_ext(data, vars, edge_val):\n",
    "    rho, lamb = data[(data.size - 6) : (data.size - 4)]\n",
    "    m, n, p, k = data[(data.size - 4) : (data.size)].astype(int)\n",
    "    nodenum = data[(data.size - 7)]\n",
    "    x = data[0:k]\n",
    "    d = data[k : (k + p)]\n",
    "    Z_k = np.concatenate(\n",
    "        (\n",
    "            vars[(edge_val[:, 0] == nodenum), :k],\n",
    "            vars[(edge_val[:, 1] == nodenum), k : 2 * k],\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    U_k = np.concatenate(\n",
    "        (\n",
    "            vars[(edge_val[:, 0] == nodenum), 2 * k : 3 * k],\n",
    "            vars[(edge_val[:, 1] == nodenum), 3 * k : 4 * k],\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    M = Z_k.shape[0]\n",
    "    AAT_inv = LA.inv(A @ A.transpose() + rho * M * np.eye(k))\n",
    "    B = (A @ d) + rho * np.sum(Z_k - U_k, axis=0)\n",
    "    xnew = AAT_inv @ B\n",
    "    return xnew\n",
    "\n",
    "\n",
    "def solveX_est_apply(all_args):\n",
    "    (func1d, axis, arr, vars, edge) = all_args\n",
    "    return np.apply_along_axis(func1d, axis, arr, vars, edge)\n",
    "\n",
    "\n",
    "def solveZ(data):\n",
    "    rho, lamb = data[(data.size - 6) : (data.size - 4)]\n",
    "    m, n, p, k = data[(data.size - 4) : (data.size)].astype(int)\n",
    "    x1 = data[0:k]\n",
    "    x2 = data[k : 2 * k]\n",
    "    u1 = data[2 * k : 3 * k]\n",
    "    u2 = data[3 * k : 4 * k]\n",
    "    weight = data[data.size - 7]\n",
    "    a = x1 + u1\n",
    "    b = x2 + u2\n",
    "    theta = np.max(\n",
    "        np.array([1 - lamb * weight / (rho * LA.norm(a - b) + 0.000001), 0.5])\n",
    "    )\n",
    "    z1 = theta * a + (1 - theta) * b\n",
    "    z2 = theta * b + (1 - theta) * a\n",
    "    znew = np.matrix(np.concatenate([z1, z2])).reshape(2 * k, 1)\n",
    "    return znew\n",
    "\n",
    "\n",
    "def solveU(data):\n",
    "    k = int(data[data.size - 1])\n",
    "    u = data[0:k]\n",
    "    x = data[k : 2 * k]\n",
    "    z = data[2 * k : 3 * k]\n",
    "    return u + (x - z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WQ5nKAD8QQA"
   },
   "outputs": [],
   "source": [
    "def runADMM(d, A, E, P, x, u, z, rho, lamb, m, n, p, k, numiters):\n",
    "    # Stopping criteria\n",
    "    eabs = math.pow(10, -3)\n",
    "    erel = math.pow(10, -4)\n",
    "    (r, s, epri, edual) = (1, 1, 0, 0)  # E = np.zeros((2*m, n))\n",
    "    (sqn, sqp) = (math.sqrt(n * k), math.sqrt(2 * k * m))\n",
    "\n",
    "    # E for dual residual\n",
    "    edge = E[:, :-1].astype(int)\n",
    "    weights = 1 / E[:, -1]\n",
    "    weights = (weights - np.min(weights)) / (np.max(weights) - np.min(weights))\n",
    "\n",
    "    # Run ADMM\n",
    "    iters = 0\n",
    "    while iters < numiters and (r > epri or s > edual or iters < 1):\n",
    "        # print(f'Iter{iters} starting...')\n",
    "        # x-update\n",
    "        zu = np.concatenate(\n",
    "            (\n",
    "                z.reshape(2 * k, m, order=\"F\").transpose(),\n",
    "                u.reshape(2 * k, m, order=\"F\").transpose(),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        temp = np.concatenate(\n",
    "            (\n",
    "                x,\n",
    "                D.transpose(),\n",
    "                np.arange(n).reshape((1, n)),\n",
    "                np.tile([rho, lamb, m, n, p, k], (n, 1)).transpose(),\n",
    "            ),\n",
    "            axis=0,\n",
    "        )\n",
    "        chunks = [\n",
    "            (solveX_ext, 1, sub_arr, zu, edge)\n",
    "            for sub_arr in np.array_split(temp.transpose(), mp.cpu_count())\n",
    "        ]\n",
    "        pool = Pool()\n",
    "        newx = pool.map(solveX_est_apply, chunks)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        xnew = np.concatenate(newx)\n",
    "        x = np.array(xnew.tolist()).transpose()  # k x n\n",
    "        # newcvxObj = np.array(values)[:,1].tolist()\n",
    "        # cvxObj = np.reshape(np.array(newcvxObj), (-1, n))\n",
    "\n",
    "        # z-update\n",
    "        ztemp = z.reshape(2 * k, m, order=\"F\")\n",
    "        utemp = u.reshape(2 * k, m, order=\"F\")\n",
    "        xtemp = np.concatenate((x[:, edge[:, 0]], x[:, edge[:, 1]]), axis=0)  # 2k x m\n",
    "        temp = np.concatenate(\n",
    "            (\n",
    "                xtemp,\n",
    "                utemp,\n",
    "                weights.reshape((1, m)),\n",
    "                np.tile([rho, lamb, m, n, p, k], (m, 1)).transpose(),\n",
    "            ),\n",
    "            axis=0,\n",
    "        )\n",
    "        chunks = [\n",
    "            (solveZ, 1, sub_arr)\n",
    "            for sub_arr in np.array_split(temp.transpose(), mp.cpu_count())\n",
    "        ]\n",
    "        pool = Pool()\n",
    "        newz = pool.map(unpack_apply, chunks)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        znew = np.concatenate(newz)\n",
    "        ztemp = np.array(znew.tolist()).transpose()\n",
    "        ztemp = ztemp.reshape(k, 2 * m, order=\"F\")  # k x 2m\n",
    "        ztemp = np.where(ztemp < 0, 0, ztemp)  # nonnegative projection\n",
    "        s = LA.norm(\n",
    "            rho * P.transpose().dot((ztemp - z).transpose())\n",
    "        )  # For dual residual\n",
    "        z = ztemp\n",
    "\n",
    "        # u-update\n",
    "        xtemp = xtemp.reshape(k, 2 * m, order=\"F\")\n",
    "        unew = u + xtemp - z\n",
    "        u = unew  # k x 2m\n",
    "\n",
    "        # Stopping criterion - p19 of ADMM paper\n",
    "        epri = sqp * eabs + erel * np.max(\n",
    "            np.array(\n",
    "                [LA.norm(x, \"fro\"), LA.norm(P.transpose().dot(z.transpose()), \"fro\")]\n",
    "            )\n",
    "        )\n",
    "        edual = sqn * eabs + erel * LA.norm(u.transpose(), \"fro\")\n",
    "        # edual = sqn*eabs + erel*LA.norm(P.transpose().dot(u.transpose()), 'fro')\n",
    "        r = LA.norm(x.transpose() - P.transpose().dot(z.transpose()), \"fro\")\n",
    "        s = s\n",
    "\n",
    "        # print r, epri, s, edual\n",
    "        iters = iters + 1\n",
    "    print(f\"{iters} iterations were run.\")\n",
    "    return (x, u, z, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check CPU cores"
   ],
   "metadata": {
    "id": "jW_9zZmixKa9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5S4a47nF_6UV",
    "outputId": "826e6680-1861-4f8c-e2ee-745ab2cd4d0b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "num_cores = mp.cpu_count()\n",
    "print(num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RUN"
   ],
   "metadata": {
    "id": "q5ldxEtRxmIK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Ahat, D, E\n",
    "root_path = \"\"\n",
    "sample_idx = [\"BALBc-1\", \"BALBc-2\", \"BALBc-3\"]\n",
    "PATH_TO_MODELS = \"spleen_tscore\"\n",
    "n_topics = [3, 5, 8, 10]\n",
    "lamb = 4  # spatial penalty\n",
    "rho = 0.1  # ADMM parameter\n",
    "numiters = 50  # Max number of ADMM iterations\n",
    "\n",
    "for sample in sample_idx:\n",
    "    print(f\"Sample {sample} starting...\")\n",
    "    print(\"---------------------------------\")\n",
    "    # Read D and edge array\n",
    "    D_path = f\"{sample}_D_unnorm\" + \".csv\"\n",
    "    E_path = f\"{sample}_edge\" + \".csv\"\n",
    "    D = pd.read_csv(root_path + D_path)\n",
    "    names = D.to_numpy()[:, 0]\n",
    "    D = D.to_numpy()[:, 1:]\n",
    "    D = D / D.sum(axis=1, keepdims=True)  # normalize to fraction\n",
    "    E = pd.read_csv(root_path + E_path)\n",
    "    E = E.to_numpy()\n",
    "\n",
    "    # Create sparse transformation matrix P (2*m,n)\n",
    "    # x = zP\n",
    "    m = E.shape[0]\n",
    "    mat = np.zeros((2 * m, 2))\n",
    "    mat[:, 0] = np.arange(0, 2 * m)\n",
    "    mat[::2, 1] = E[:, 0]\n",
    "    mat[1::2, 1] = E[:, 1]\n",
    "    row = mat[:, 0]\n",
    "    col = mat[:, 1]\n",
    "    data = np.ones(2 * m)\n",
    "    P_unnorm = coo_array((data, (row.astype(int), col.astype(int)))).tocsr()\n",
    "    count = np.array(P_unnorm.sum(axis=0)).flatten()\n",
    "    P = P_unnorm.multiply(1 / count)  # 2m*n\n",
    "    # np.sum(P.transpose().dot(z.transpose())-x.transpose()) # should be near 0\n",
    "\n",
    "    # Iterate for each n_topic\n",
    "    for n_topic in n_topics:\n",
    "        print(f\"Running n_topics={n_topic}, lambda={lamb}\\n\")\n",
    "        t = time.time()\n",
    "        path_to_train_model = (\n",
    "            \"_\".join(\n",
    "                (\n",
    "                    f\"{PATH_TO_MODELS}\",\n",
    "                    f\"{sample}\",\n",
    "                    f\"penalty={lamb}\",\n",
    "                    f\"topics={n_topic}\",\n",
    "                )\n",
    "            )\n",
    "            + \".pkl\"\n",
    "        )\n",
    "        # Read Ahat\n",
    "        Ahat_path = f\"{sample}_Ahat_\" + f\"{n_topic}\" + \".csv\"\n",
    "        Ahat = pd.read_csv(root_path + Ahat_path)\n",
    "        A = Ahat.to_numpy().transpose()\n",
    "        n, p = D.shape\n",
    "        k = A.shape[0]\n",
    "        # Set initial parameters\n",
    "        x = np.zeros((k, n))\n",
    "        z = np.zeros((k, 2 * m))\n",
    "        u = np.zeros((k, 2 * m))\n",
    "        # Run\n",
    "        rhoval = np.min(np.array([lamb + 0.00001, rho + lamb / 25]))\n",
    "        (x, u, z, pl1, pl2) = runADMM(\n",
    "            D, A, E, P, x, u, z, rhoval, lamb, m, n, p, k, numiters\n",
    "        )\n",
    "        elapsed = time.time() - t\n",
    "        print(f\"Elapsed time={elapsed}\\n\")\n",
    "        with open(path_to_train_model, \"wb\") as f:\n",
    "            pkl.dump(x, f)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l4M26mfIngrv",
    "outputId": "216d5a4a-fd3c-4ace-e2f4-04618f31df1e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample BALBc-1 starting...\n",
      "---------------------------------\n",
      "Running n_topics=3, lambda=4\n",
      "\n",
      "16 iterations were run.\n",
      "Elapsed time=1371.316017150879\n",
      "\n",
      "Running n_topics=5, lambda=4\n",
      "\n",
      "14 iterations were run.\n",
      "Elapsed time=1570.261428117752\n",
      "\n",
      "Running n_topics=8, lambda=4\n",
      "\n",
      "10 iterations were run.\n",
      "Elapsed time=1131.2875337600708\n",
      "\n",
      "Running n_topics=10, lambda=4\n",
      "\n",
      "9 iterations were run.\n",
      "Elapsed time=1044.0989921092987\n",
      "\n",
      "Sample BALBc-2 starting...\n",
      "---------------------------------\n",
      "Running n_topics=3, lambda=4\n",
      "\n",
      "15 iterations were run.\n",
      "Elapsed time=1201.2846179008484\n",
      "\n",
      "Running n_topics=5, lambda=4\n",
      "\n",
      "12 iterations were run.\n",
      "Elapsed time=1244.5845758914948\n",
      "\n",
      "Running n_topics=8, lambda=4\n",
      "\n",
      "10 iterations were run.\n",
      "Elapsed time=1040.165302991867\n",
      "\n",
      "Running n_topics=10, lambda=4\n",
      "\n",
      "10 iterations were run.\n",
      "Elapsed time=1053.6275823116302\n",
      "\n",
      "Sample BALBc-3 starting...\n",
      "---------------------------------\n",
      "Running n_topics=3, lambda=4\n",
      "\n",
      "14 iterations were run.\n",
      "Elapsed time=1018.6702148914337\n",
      "\n",
      "Running n_topics=5, lambda=4\n",
      "\n",
      "10 iterations were run.\n",
      "Elapsed time=897.1824901103973\n",
      "\n",
      "Running n_topics=8, lambda=4\n",
      "\n",
      "12 iterations were run.\n",
      "Elapsed time=1102.313993215561\n",
      "\n",
      "Running n_topics=10, lambda=4\n",
      "\n",
      "11 iterations were run.\n",
      "Elapsed time=1005.5163776874542\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import files\n",
    "# files.download('no_spatial_11')"
   ],
   "metadata": {
    "id": "KaKBmHH3wCCL"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}